{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled7.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"dD5wE98QRydh","colab_type":"code","outputId":"817601d0-9b30-493f-d0c6-86d551b19050","executionInfo":{"status":"ok","timestamp":1566452965292,"user_tz":-330,"elapsed":4058,"user":{"displayName":"Kushagra Bhatia","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8m2Hqe_J_VckJ1PlnRCIhfLS2zsKUH5E0SzgRfA=s64","userId":"12476490699397159076"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import pandas as pd\n","import numpy as np\n","\n","from keras.preprocessing.text import Tokenizer\n","from keras.engine.topology import Layer\n","from keras import initializers as initializers, regularizers, constraints\n","from keras.callbacks import Callback\n","from keras.layers import Embedding, Input, Dense, LSTM, GRU, Bidirectional, TimeDistributed\n","from keras import backend as K\n","from keras.models import Model\n","\n","\n","from sklearn.metrics import roc_auc_score"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qJeo-CtNd7dI","colab_type":"code","outputId":"1ef6f857-5a3d-4b81-ac53-f3c922daebc5","executionInfo":{"status":"ok","timestamp":1566452965316,"user_tz":-330,"elapsed":739,"user":{"displayName":"Kushagra Bhatia","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8m2Hqe_J_VckJ1PlnRCIhfLS2zsKUH5E0SzgRfA=s64","userId":"12476490699397159076"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd /content/drive/My Drive/Colab Notebooks/HAN"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/HAN\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fGRBLv4xIiRS","colab_type":"code","colab":{}},"source":["# %load char-rnn.py\n","import numpy as np\n","import h5py\n","import pickle\n","from copy import deepcopy\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.preprocessing import sequence\n","from keras import backend as K\n","from keras.layers.core import Dense, Dropout, Activation\n","from keras.layers.embeddings import Embedding\n","from keras.layers.recurrent import LSTM, GRU\n","from keras.layers.convolutional import Convolution1D, MaxPooling1D\n","from keras.layers import Conv1D\n","import tensorflow as tf\n","\n","from keras.utils import np_utils\n","from MyNormalizer import token\n","\n","################# GLOBAL VARIABLES #####################\n","#Filenames\n","\n","inputdatasetfilename = 'IIITH_Codemixed.txt'\n","\n","#Data I/O formatting\n","SEPERATOR = '\\t'\n","DATA_COLUMN = 1\n","LABEL_COLUMN = 3\n","LABELS = ['0','1','2'] # 0 -> Negative, 1-> Neutral, 2-> Positive\n","mapping_char2num = {}\n","mapping_num2char = {}\n","MAXLEN = 200\n","\n","#LSTM Model Parameters\n","#Embedding\n","MAX_FEATURES = 0\n","embedding_size = 128\n","# Convolution\n","filter_length = 3\n","nb_filter = 128\n","pool_length = 3\n","# LSTM\n","lstm_output_size = 128\n","# Training\n","batch_size = 128\n","number_of_epochs = 80\n","numclasses = 3\n","test_size = 0.2\n","MAX_WORD_LENGTH = 7\n","MAX_WORDS = 20\n","MAX_NB_CHARS = 1000\n","EMBEDDING_DIM = 10\n","VALIDATION_SPLIT = 0.2\n","########################################################"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BVNC0CGZIw1j","colab_type":"code","outputId":"ec781c5e-5bee-4033-ba95-2bd7ccda0321","executionInfo":{"status":"ok","timestamp":1572415912946,"user_tz":-330,"elapsed":31141,"user":{"displayName":"Kushagra Bhatia","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8m2Hqe_J_VckJ1PlnRCIhfLS2zsKUH5E0SzgRfA=s64","userId":"12476490699397159076"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["def par(filename,seperator,labelcol,labels):\n","  f=open(filename,'r',encoding='utf-8')\n","  lines=f.read().lower()\n","  lines=lines.lower().split('\\n')[:-1]\n","  sentences = [l.split(seperator) for l in lines]\n","  sentences=[s[1] for s in sentences]\n","  tokenizer = Tokenizer(num_words=MAX_NB_CHARS, char_level=True)\n","  tokenizer.fit_on_texts(sentences)\n","  data = np.zeros((len(sentences), MAX_WORDS, MAX_WORD_LENGTH), dtype='int32')\n","  for i, words in enumerate(sentences):\n","    for j, word in enumerate(words):\n","        if j < MAX_WORDS:\n","            k = 0\n","            for _, char in enumerate(word):\n","                try:\n","                    if k < MAX_WORD_LENGTH:\n","                        if tokenizer.word_index[char] < MAX_NB_CHARS:\n","                            data[i, j, k] = tokenizer.word_index[char]\n","                            k=k+1\n","                except:\n","                    None\n","  char_index = tokenizer.word_index\n","  lab=[]\n","  for line in lines:\n","    line=line.split(seperator)\n","    if(line[labelcol]==labels[0]):\n","      lab.append(0)\n","    if(line[labelcol]==labels[1]):\n","      lab.append(1)\n","    if(line[labelcol]==labels[2]):\n","      lab.append(2)\n","  lab=np.array(lab)\n","  indices = np.arange(data.shape[0])\n","  np.random.shuffle(indices)\n","  data = data[indices]\n","  lab = lab[indices]\n","  \n","  nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n","  \n","    \n","  x_train = data[:-nb_validation_samples]\n","  y_train = lab[:-nb_validation_samples]\n","  x_val = data[-nb_validation_samples:]\n","  y_val = lab[-nb_validation_samples:]\n","  y_train=tf.keras.utils.to_categorical(y_train)\n","  y_val=tf.keras.utils.to_categorical(y_val)\n","\n","  return (x_train,y_train,x_val,y_val,char_index)\n","par(inputdatasetfilename,SEPERATOR,LABEL_COLUMN,LABELS)\n","  "],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[[ 8,  0,  0, ...,  0,  0,  0],\n","         [18,  0,  0, ...,  0,  0,  0],\n","         [ 5,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [ 2,  0,  0, ...,  0,  0,  0],\n","         [14,  0,  0, ...,  0,  0,  0],\n","         [ 1,  0,  0, ...,  0,  0,  0]],\n"," \n","        [[ 2,  0,  0, ...,  0,  0,  0],\n","         [21,  0,  0, ...,  0,  0,  0],\n","         [ 2,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [ 7,  0,  0, ...,  0,  0,  0],\n","         [ 5,  0,  0, ...,  0,  0,  0],\n","         [ 9,  0,  0, ...,  0,  0,  0]],\n"," \n","        [[10,  0,  0, ...,  0,  0,  0],\n","         [16,  0,  0, ...,  0,  0,  0],\n","         [17,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [ 2,  0,  0, ...,  0,  0,  0],\n","         [ 4,  0,  0, ...,  0,  0,  0],\n","         [ 5,  0,  0, ...,  0,  0,  0]],\n"," \n","        ...,\n"," \n","        [[ 4,  0,  0, ...,  0,  0,  0],\n","         [11,  0,  0, ...,  0,  0,  0],\n","         [12,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [ 4,  0,  0, ...,  0,  0,  0],\n","         [ 2,  0,  0, ...,  0,  0,  0],\n","         [ 3,  0,  0, ...,  0,  0,  0]],\n"," \n","        [[10,  0,  0, ...,  0,  0,  0],\n","         [ 2,  0,  0, ...,  0,  0,  0],\n","         [13,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [22,  0,  0, ...,  0,  0,  0],\n","         [ 7,  0,  0, ...,  0,  0,  0],\n","         [ 1,  0,  0, ...,  0,  0,  0]],\n"," \n","        [[ 7,  0,  0, ...,  0,  0,  0],\n","         [18,  0,  0, ...,  0,  0,  0],\n","         [ 2,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [ 2,  0,  0, ...,  0,  0,  0],\n","         [ 3,  0,  0, ...,  0,  0,  0],\n","         [ 6,  0,  0, ...,  0,  0,  0]]], dtype=int32), array([[1., 0., 0.],\n","        [1., 0., 0.],\n","        [0., 0., 1.],\n","        ...,\n","        [0., 1., 0.],\n","        [0., 0., 1.],\n","        [1., 0., 0.]], dtype=float32), array([[[ 8,  0,  0, ...,  0,  0,  0],\n","         [ 7,  0,  0, ...,  0,  0,  0],\n","         [ 1,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [ 3,  0,  0, ...,  0,  0,  0],\n","         [ 6,  0,  0, ...,  0,  0,  0],\n","         [ 1,  0,  0, ...,  0,  0,  0]],\n"," \n","        [[11,  0,  0, ...,  0,  0,  0],\n","         [ 2,  0,  0, ...,  0,  0,  0],\n","         [10,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [ 6,  0,  0, ...,  0,  0,  0],\n","         [ 0,  0,  0, ...,  0,  0,  0],\n","         [ 0,  0,  0, ...,  0,  0,  0]],\n"," \n","        [[ 2,  0,  0, ...,  0,  0,  0],\n","         [10,  0,  0, ...,  0,  0,  0],\n","         [10,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [ 4,  0,  0, ...,  0,  0,  0],\n","         [ 2,  0,  0, ...,  0,  0,  0],\n","         [ 3,  0,  0, ...,  0,  0,  0]],\n"," \n","        ...,\n"," \n","        [[ 4,  0,  0, ...,  0,  0,  0],\n","         [ 3,  0,  0, ...,  0,  0,  0],\n","         [ 3,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [11,  0,  0, ...,  0,  0,  0],\n","         [ 5,  0,  0, ...,  0,  0,  0],\n","         [ 1,  0,  0, ...,  0,  0,  0]],\n"," \n","        [[14,  0,  0, ...,  0,  0,  0],\n","         [ 4,  0,  0, ...,  0,  0,  0],\n","         [ 2,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [ 5,  0,  0, ...,  0,  0,  0],\n","         [ 9,  0,  0, ...,  0,  0,  0],\n","         [ 1,  0,  0, ...,  0,  0,  0]],\n"," \n","        [[ 2,  0,  0, ...,  0,  0,  0],\n","         [ 9,  0,  0, ...,  0,  0,  0],\n","         [ 5,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [ 4,  0,  0, ...,  0,  0,  0],\n","         [ 3,  0,  0, ...,  0,  0,  0],\n","         [ 1,  0,  0, ...,  0,  0,  0]]], dtype=int32), array([[0., 0., 1.],\n","        [0., 0., 1.],\n","        [0., 1., 0.],\n","        ...,\n","        [0., 1., 0.],\n","        [0., 1., 0.],\n","        [0., 1., 0.]], dtype=float32), {'\\x08': 82,\n","  ' ': 1,\n","  '!': 38,\n","  '\"': 50,\n","  '#': 42,\n","  '$': 60,\n","  '%': 77,\n","  '&': 58,\n","  \"'\": 34,\n","  '(': 43,\n","  ')': 39,\n","  '*': 35,\n","  '+': 55,\n","  ',': 29,\n","  '-': 40,\n","  '.': 15,\n","  '/': 59,\n","  '0': 30,\n","  '1': 36,\n","  '2': 41,\n","  '3': 28,\n","  '4': 33,\n","  '5': 44,\n","  '6': 46,\n","  '7': 45,\n","  '8': 47,\n","  '9': 48,\n","  ':': 32,\n","  ';': 52,\n","  '<': 31,\n","  '=': 76,\n","  '>': 62,\n","  '?': 27,\n","  '@': 57,\n","  '[': 81,\n","  '\\\\': 75,\n","  '^': 67,\n","  '_': 53,\n","  '`': 74,\n","  'a': 2,\n","  'b': 14,\n","  'c': 22,\n","  'd': 19,\n","  'e': 5,\n","  'f': 23,\n","  'g': 21,\n","  'h': 4,\n","  'i': 3,\n","  'j': 20,\n","  'k': 7,\n","  'l': 13,\n","  'm': 11,\n","  'n': 6,\n","  'o': 8,\n","  'p': 17,\n","  'q': 37,\n","  'r': 9,\n","  's': 10,\n","  't': 12,\n","  'u': 16,\n","  'v': 26,\n","  'w': 24,\n","  'x': 49,\n","  'y': 18,\n","  'z': 25,\n","  '~': 61,\n","  '\\xa0': 66,\n","  '¡': 63,\n","  '¤': 73,\n","  '¦': 56,\n","  '«': 64,\n","  '²': 79,\n","  '¹': 71,\n","  'â': 51,\n","  'ã': 68,\n","  'å': 65,\n","  'ž': 69,\n","  '˜': 72,\n","  '–': 78,\n","  '’': 70,\n","  '”': 80,\n","  '€': 54})"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"j84TbZoUbcB6","colab_type":"code","colab":{}},"source":["    out = par(inputdatasetfilename,SEPERATOR,LABEL_COLUMN,LABELS)\n","    global x_train\n","    global y_train\n","    global x_test\n","    global y_test\n","    x_train = out[0]\n","    y_train = out[1]\n","    x_val=out[2]\n","    y_val=out[3]\n","    char_index=out[4]\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JTJo_ABACWWJ","colab_type":"code","outputId":"4ac48ae3-3422-47e9-a186-d4d3db366dd6","executionInfo":{"status":"ok","timestamp":1572415912967,"user_tz":-330,"elapsed":12507,"user":{"displayName":"Kushagra Bhatia","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8m2Hqe_J_VckJ1PlnRCIhfLS2zsKUH5E0SzgRfA=s64","userId":"12476490699397159076"}},"colab":{"base_uri":"https://localhost:8080/","height":888}},"source":["print(x_train)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["[[[18  0  0 ...  0  0  0]\n","  [ 5  0  0 ...  0  0  0]\n","  [ 1  0  0 ...  0  0  0]\n","  ...\n","  [10  0  0 ...  0  0  0]\n","  [16  0  0 ...  0  0  0]\n","  [17  0  0 ...  0  0  0]]\n","\n"," [[14  0  0 ...  0  0  0]\n","  [ 4  0  0 ...  0  0  0]\n","  [ 2  0  0 ...  0  0  0]\n","  ...\n","  [ 3  0  0 ...  0  0  0]\n","  [ 1  0  0 ...  0  0  0]\n","  [ 2  0  0 ...  0  0  0]]\n","\n"," [[24  0  0 ...  0  0  0]\n","  [ 2  0  0 ...  0  0  0]\n","  [ 4  0  0 ...  0  0  0]\n","  ...\n","  [16  0  0 ...  0  0  0]\n","  [12  0  0 ...  0  0  0]\n","  [ 1  0  0 ...  0  0  0]]\n","\n"," ...\n","\n"," [[11  0  0 ...  0  0  0]\n","  [ 2  0  0 ...  0  0  0]\n","  [10  0  0 ...  0  0  0]\n","  ...\n","  [ 0  0  0 ...  0  0  0]\n","  [ 0  0  0 ...  0  0  0]\n","  [ 0  0  0 ...  0  0  0]]\n","\n"," [[ 4  0  0 ...  0  0  0]\n","  [13  0  0 ...  0  0  0]\n","  [24  0  0 ...  0  0  0]\n","  ...\n","  [ 1  0  0 ...  0  0  0]\n","  [12  0  0 ...  0  0  0]\n","  [ 8  0  0 ...  0  0  0]]\n","\n"," [[10  0  0 ...  0  0  0]\n","  [ 3  0  0 ...  0  0  0]\n","  [ 9  0  0 ...  0  0  0]\n","  ...\n","  [ 9  0  0 ...  0  0  0]\n","  [ 1  0  0 ...  0  0  0]\n","  [14  0  0 ...  0  0  0]]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qBXOhBnM4wuF","colab_type":"code","outputId":"ddaab573-8adb-484a-a5ed-ae29258183e3","executionInfo":{"status":"ok","timestamp":1572415912971,"user_tz":-330,"elapsed":10338,"user":{"displayName":"Kushagra Bhatia","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8m2Hqe_J_VckJ1PlnRCIhfLS2zsKUH5E0SzgRfA=s64","userId":"12476490699397159076"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["x_train.shape"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3104, 20, 7)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"wBg1QyOMR2tS","colab_type":"code","colab":{}},"source":["def dot_product(x, kernel):\n","    \"\"\"\n","    Wrapper for dot product operation, in order to be compatible with both\n","    Theano and Tensorflow\n","    Args:\n","        x (): input\n","        kernel (): weights\n","    Returns:\n","    \"\"\"\n","    if K.backend() == 'tensorflow':\n","        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n","    else:\n","        return K.dot(x, kernel)\n","\n","class AttentionWithContext(Layer):\n","    \"\"\"\n","    Attention operation, with a context/query vector, for temporal data.\n","    Supports Masking.\n","    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n","    \"Hierarchical Attention Networks for Document Classification\"\n","    by using a context vector to assist the attention\n","    # Input shape\n","        3D tensor with shape: `(samples, steps, features)`.\n","    # Output shape\n","        2D tensor with shape: `(samples, features)`.\n","    \"\"\"\n","\n","    def __init__(self,\n","                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n","                 W_constraint=None, u_constraint=None, b_constraint=None,\n","                 bias=True, **kwargs):\n","\n","        self.supports_masking = True\n","        self.init = initializers.get('glorot_uniform')\n","\n","        self.W_regularizer = regularizers.get(W_regularizer)\n","        self.u_regularizer = regularizers.get(u_regularizer)\n","        self.b_regularizer = regularizers.get(b_regularizer)\n","\n","        self.W_constraint = constraints.get(W_constraint)\n","        self.u_constraint = constraints.get(u_constraint)\n","        self.b_constraint = constraints.get(b_constraint)\n","\n","        self.bias = bias\n","        super(AttentionWithContext, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 3\n","\n","        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_W'.format(self.name),\n","                                 regularizer=self.W_regularizer,\n","                                 constraint=self.W_constraint)\n","        if self.bias:\n","            self.b = self.add_weight((input_shape[-1],),\n","                                     initializer='zero',\n","                                     name='{}_b'.format(self.name),\n","                                     regularizer=self.b_regularizer,\n","                                     constraint=self.b_constraint)\n","\n","        self.u = self.add_weight((input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_u'.format(self.name),\n","                                 regularizer=self.u_regularizer,\n","                                 constraint=self.u_constraint)\n","\n","        super(AttentionWithContext, self).build(input_shape)\n","\n","    def compute_mask(self, input, input_mask=None):\n","        return None\n","\n","    def call(self, x, mask=None):\n","        uit = dot_product(x, self.W)\n","\n","        if self.bias:\n","            uit += self.b\n","\n","        uit = K.tanh(uit)\n","        ait = dot_product(uit, self.u)\n","\n","        a = K.exp(ait)\n","\n","        if mask is not None:\n","            a *= K.cast(mask, K.floatx())\n","\n","        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n","\n","        a = K.expand_dims(a)\n","        weighted_input = x * a\n","        return K.sum(weighted_input, axis=1)\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape[0], input_shape[-1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XOaH4X4BSO0u","colab_type":"code","colab":{}},"source":["class RocAucEvaluation(Callback):\n","    def __init__(self, validation_data=(), interval=1):\n","        super(Callback, self).__init__()\n","\n","        self.interval = interval\n","        self.X_val, self.y_val = validation_data\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        if epoch % self.interval == 0:\n","            y_pred = self.model.predict(self.X_val, verbose=0)\n","            score = roc_auc_score(self.y_val, y_pred)\n","            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XlNlb12lSRXl","colab_type":"code","outputId":"45debafd-1562-4016-9346-7097edfaf402","executionInfo":{"status":"ok","timestamp":1572415937221,"user_tz":-330,"elapsed":2395,"user":{"displayName":"Kushagra Bhatia","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8m2Hqe_J_VckJ1PlnRCIhfLS2zsKUH5E0SzgRfA=s64","userId":"12476490699397159076"}},"colab":{"base_uri":"https://localhost:8080/","height":108}},"source":["embedding_layer = Embedding(len(char_index) + 1,\n","                            EMBEDDING_DIM,\n","                            input_length=MAX_WORD_LENGTH,\n","                            trainable=True)\n","\n","char_input = Input(shape=(MAX_WORD_LENGTH,), dtype='int32')\n","char_sequences = embedding_layer(char_input)\n","char_conv=Convolution1D(nb_filter=nb_filter,\n","\t\t\t\t\t\t\tfilter_length=filter_length,\n","\t\t\t\t\t\t\tborder_mode='valid',\n","\t\t\t\t\t\t\tactivation='relu',\n","\t\t\t\t\t\t\tsubsample_length=1)(char_sequences)\n","char_maxpool=MaxPooling1D(pool_length=pool_length)(char_conv)\n","char_lstm = Bidirectional(LSTM(100, return_sequences=True))(char_maxpool)\n","char_dense = TimeDistributed(Dense(200))(char_lstm)\n","char_att = AttentionWithContext()(char_dense)\n","charEncoder = Model(char_input, char_att)\n","\n","words_input = Input(shape=(MAX_WORDS, MAX_WORD_LENGTH), dtype='int32')\n","words_encoder = TimeDistributed(charEncoder)(words_input)\n","words_lstm = Bidirectional(LSTM(100, return_sequences=True))(words_encoder)\n","words_dense = TimeDistributed(Dense(200))(words_lstm)\n","words_att = AttentionWithContext()(words_dense)\n","preds = Dense(3, activation='softmax')(words_att)\n","model = Model(words_input, preds)\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adamax',\n","              metrics=['acc'])"],"execution_count":20,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=128, kernel_size=3, strides=1, padding=\"valid\")`\n","  if sys.path[0] == '':\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=3)`\n","  del sys.path[0]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"2xrpLqaOST2H","colab_type":"code","outputId":"5c7d4ee0-1baa-42b2-d3fd-8e2a85866a0e","executionInfo":{"status":"ok","timestamp":1572416967110,"user_tz":-330,"elapsed":1029345,"user":{"displayName":"Kushagra Bhatia","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8m2Hqe_J_VckJ1PlnRCIhfLS2zsKUH5E0SzgRfA=s64","userId":"12476490699397159076"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["RocAuc = RocAucEvaluation(validation_data=(x_val, y_val), interval=1)\n","model.fit(x_train, y_train, validation_data=(x_val, y_val),\n","          epochs=100, batch_size=64)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Train on 3104 samples, validate on 775 samples\n","Epoch 1/100\n","3104/3104 [==============================] - 14s 5ms/step - loss: 1.0062 - acc: 0.4977 - val_loss: 0.9998 - val_acc: 0.5097\n","Epoch 2/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9975 - acc: 0.5032 - val_loss: 0.9945 - val_acc: 0.5097\n","Epoch 3/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9962 - acc: 0.5032 - val_loss: 0.9972 - val_acc: 0.5097\n","Epoch 4/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9960 - acc: 0.5032 - val_loss: 0.9942 - val_acc: 0.5097\n","Epoch 5/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9938 - acc: 0.5032 - val_loss: 0.9867 - val_acc: 0.5097\n","Epoch 6/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9789 - acc: 0.5032 - val_loss: 0.9769 - val_acc: 0.5097\n","Epoch 7/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9676 - acc: 0.5174 - val_loss: 0.9656 - val_acc: 0.5523\n","Epoch 8/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9561 - acc: 0.5374 - val_loss: 0.9635 - val_acc: 0.5548\n","Epoch 9/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9428 - acc: 0.5525 - val_loss: 0.9607 - val_acc: 0.5432\n","Epoch 10/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9411 - acc: 0.5551 - val_loss: 0.9493 - val_acc: 0.5419\n","Epoch 11/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9345 - acc: 0.5577 - val_loss: 0.9521 - val_acc: 0.5510\n","Epoch 12/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9323 - acc: 0.5570 - val_loss: 0.9508 - val_acc: 0.5432\n","Epoch 13/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9315 - acc: 0.5541 - val_loss: 0.9481 - val_acc: 0.5600\n","Epoch 14/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9333 - acc: 0.5541 - val_loss: 0.9396 - val_acc: 0.5523\n","Epoch 15/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9210 - acc: 0.5644 - val_loss: 0.9572 - val_acc: 0.5548\n","Epoch 16/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9279 - acc: 0.5580 - val_loss: 0.9409 - val_acc: 0.5548\n","Epoch 17/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9186 - acc: 0.5741 - val_loss: 0.9349 - val_acc: 0.5652\n","Epoch 18/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9152 - acc: 0.5702 - val_loss: 0.9296 - val_acc: 0.5626\n","Epoch 19/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9188 - acc: 0.5612 - val_loss: 0.9338 - val_acc: 0.5600\n","Epoch 20/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9173 - acc: 0.5660 - val_loss: 0.9476 - val_acc: 0.5497\n","Epoch 21/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9174 - acc: 0.5670 - val_loss: 0.9361 - val_acc: 0.5484\n","Epoch 22/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9154 - acc: 0.5683 - val_loss: 0.9666 - val_acc: 0.5394\n","Epoch 23/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9169 - acc: 0.5602 - val_loss: 0.9323 - val_acc: 0.5613\n","Epoch 24/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9082 - acc: 0.5660 - val_loss: 0.9481 - val_acc: 0.5523\n","Epoch 25/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9095 - acc: 0.5664 - val_loss: 0.9422 - val_acc: 0.5652\n","Epoch 26/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9064 - acc: 0.5693 - val_loss: 0.9372 - val_acc: 0.5613\n","Epoch 27/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9062 - acc: 0.5670 - val_loss: 0.9297 - val_acc: 0.5600\n","Epoch 28/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9052 - acc: 0.5722 - val_loss: 0.9352 - val_acc: 0.5523\n","Epoch 29/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8989 - acc: 0.5696 - val_loss: 0.9465 - val_acc: 0.5381\n","Epoch 30/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9008 - acc: 0.5725 - val_loss: 0.9253 - val_acc: 0.5523\n","Epoch 31/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.9048 - acc: 0.5657 - val_loss: 0.9277 - val_acc: 0.5445\n","Epoch 32/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8956 - acc: 0.5664 - val_loss: 0.9206 - val_acc: 0.5561\n","Epoch 33/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8968 - acc: 0.5715 - val_loss: 0.9314 - val_acc: 0.5419\n","Epoch 34/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8899 - acc: 0.5680 - val_loss: 0.9215 - val_acc: 0.5561\n","Epoch 35/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8875 - acc: 0.5693 - val_loss: 0.9661 - val_acc: 0.5510\n","Epoch 36/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8884 - acc: 0.5725 - val_loss: 0.9265 - val_acc: 0.5535\n","Epoch 37/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8866 - acc: 0.5744 - val_loss: 0.9257 - val_acc: 0.5548\n","Epoch 38/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8757 - acc: 0.5747 - val_loss: 0.9248 - val_acc: 0.5432\n","Epoch 39/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8700 - acc: 0.5812 - val_loss: 0.9158 - val_acc: 0.5458\n","Epoch 40/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8694 - acc: 0.5780 - val_loss: 0.9252 - val_acc: 0.5419\n","Epoch 41/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8745 - acc: 0.5789 - val_loss: 0.9241 - val_acc: 0.5381\n","Epoch 42/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8653 - acc: 0.5818 - val_loss: 0.9135 - val_acc: 0.5406\n","Epoch 43/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8620 - acc: 0.5789 - val_loss: 0.9220 - val_acc: 0.5523\n","Epoch 44/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8634 - acc: 0.5880 - val_loss: 0.9131 - val_acc: 0.5639\n","Epoch 45/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8581 - acc: 0.5892 - val_loss: 0.9303 - val_acc: 0.5574\n","Epoch 46/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8586 - acc: 0.5973 - val_loss: 0.9211 - val_acc: 0.5561\n","Epoch 47/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8541 - acc: 0.5970 - val_loss: 0.9287 - val_acc: 0.5665\n","Epoch 48/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8522 - acc: 0.5841 - val_loss: 0.9052 - val_acc: 0.5794\n","Epoch 49/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8521 - acc: 0.5925 - val_loss: 0.9411 - val_acc: 0.5523\n","Epoch 50/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8516 - acc: 0.5867 - val_loss: 0.9224 - val_acc: 0.5445\n","Epoch 51/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8428 - acc: 0.6060 - val_loss: 0.9257 - val_acc: 0.5626\n","Epoch 52/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8357 - acc: 0.6066 - val_loss: 0.9256 - val_acc: 0.5600\n","Epoch 53/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8416 - acc: 0.6002 - val_loss: 0.9265 - val_acc: 0.5587\n","Epoch 54/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8324 - acc: 0.6034 - val_loss: 0.9333 - val_acc: 0.5690\n","Epoch 55/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8286 - acc: 0.6047 - val_loss: 0.9491 - val_acc: 0.5523\n","Epoch 56/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8239 - acc: 0.6121 - val_loss: 0.9190 - val_acc: 0.5626\n","Epoch 57/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8192 - acc: 0.6082 - val_loss: 0.9721 - val_acc: 0.5497\n","Epoch 58/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8285 - acc: 0.6128 - val_loss: 0.9575 - val_acc: 0.5574\n","Epoch 59/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8221 - acc: 0.6160 - val_loss: 0.9402 - val_acc: 0.5484\n","Epoch 60/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8083 - acc: 0.6208 - val_loss: 0.9485 - val_acc: 0.5497\n","Epoch 61/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8112 - acc: 0.6169 - val_loss: 0.9494 - val_acc: 0.5432\n","Epoch 62/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.8030 - acc: 0.6292 - val_loss: 0.9425 - val_acc: 0.5523\n","Epoch 63/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.7940 - acc: 0.6282 - val_loss: 0.9444 - val_acc: 0.5639\n","Epoch 64/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.7881 - acc: 0.6337 - val_loss: 0.9598 - val_acc: 0.5665\n","Epoch 65/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.7792 - acc: 0.6398 - val_loss: 0.9917 - val_acc: 0.5303\n","Epoch 66/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.7722 - acc: 0.6398 - val_loss: 0.9645 - val_acc: 0.5574\n","Epoch 67/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.7653 - acc: 0.6389 - val_loss: 0.9589 - val_acc: 0.5600\n","Epoch 68/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.7525 - acc: 0.6495 - val_loss: 0.9917 - val_acc: 0.5690\n","Epoch 69/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.7406 - acc: 0.6588 - val_loss: 1.0173 - val_acc: 0.5303\n","Epoch 70/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.7371 - acc: 0.6534 - val_loss: 0.9730 - val_acc: 0.5626\n","Epoch 71/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.7373 - acc: 0.6495 - val_loss: 1.0105 - val_acc: 0.5587\n","Epoch 72/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.7397 - acc: 0.6517 - val_loss: 1.0160 - val_acc: 0.5561\n","Epoch 73/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.7211 - acc: 0.6656 - val_loss: 1.0305 - val_acc: 0.5484\n","Epoch 74/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.7032 - acc: 0.6730 - val_loss: 1.0503 - val_acc: 0.5561\n","Epoch 75/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.6861 - acc: 0.6881 - val_loss: 1.0614 - val_acc: 0.5458\n","Epoch 76/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.6852 - acc: 0.6859 - val_loss: 1.0832 - val_acc: 0.5458\n","Epoch 77/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.6748 - acc: 0.6898 - val_loss: 1.0818 - val_acc: 0.5458\n","Epoch 78/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.6520 - acc: 0.7001 - val_loss: 1.1550 - val_acc: 0.5123\n","Epoch 79/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.6318 - acc: 0.7107 - val_loss: 1.1443 - val_acc: 0.5329\n","Epoch 80/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.6264 - acc: 0.7162 - val_loss: 1.1694 - val_acc: 0.5458\n","Epoch 81/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.6176 - acc: 0.7197 - val_loss: 1.2146 - val_acc: 0.5303\n","Epoch 82/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.6018 - acc: 0.7303 - val_loss: 1.2250 - val_acc: 0.5265\n","Epoch 83/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.5844 - acc: 0.7394 - val_loss: 1.2312 - val_acc: 0.5445\n","Epoch 84/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.5856 - acc: 0.7387 - val_loss: 1.2289 - val_acc: 0.5394\n","Epoch 85/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.5577 - acc: 0.7481 - val_loss: 1.2995 - val_acc: 0.5329\n","Epoch 86/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.5348 - acc: 0.7626 - val_loss: 1.3586 - val_acc: 0.5290\n","Epoch 87/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.5225 - acc: 0.7732 - val_loss: 1.3345 - val_acc: 0.5394\n","Epoch 88/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.4997 - acc: 0.7774 - val_loss: 1.4269 - val_acc: 0.5045\n","Epoch 89/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.4853 - acc: 0.7903 - val_loss: 1.4353 - val_acc: 0.5174\n","Epoch 90/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.4691 - acc: 0.7967 - val_loss: 1.4955 - val_acc: 0.5226\n","Epoch 91/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.4519 - acc: 0.7999 - val_loss: 1.5571 - val_acc: 0.5445\n","Epoch 92/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.4252 - acc: 0.8183 - val_loss: 1.5957 - val_acc: 0.5135\n","Epoch 93/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.4096 - acc: 0.8254 - val_loss: 1.7348 - val_acc: 0.5381\n","Epoch 94/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.4053 - acc: 0.8251 - val_loss: 1.6999 - val_acc: 0.4942\n","Epoch 95/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.3868 - acc: 0.8280 - val_loss: 1.7272 - val_acc: 0.5123\n","Epoch 96/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.3483 - acc: 0.8450 - val_loss: 1.7833 - val_acc: 0.5174\n","Epoch 97/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.3303 - acc: 0.8599 - val_loss: 1.8667 - val_acc: 0.5174\n","Epoch 98/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.3136 - acc: 0.8702 - val_loss: 1.9208 - val_acc: 0.5161\n","Epoch 99/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.2967 - acc: 0.8682 - val_loss: 1.9977 - val_acc: 0.5252\n","Epoch 100/100\n","3104/3104 [==============================] - 10s 3ms/step - loss: 0.2847 - acc: 0.8769 - val_loss: 2.1524 - val_acc: 0.5019\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fae0b509c50>"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"RRCivn51ekVN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}